{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "from api_keys import cohere_api_key, open_ai_api_key\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents\n",
    "\n",
    "Documents comes from https://github.com/huggingface/transformers/blob/main/awesome-transformers.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n\\nAwesome projects built with Transformers\\n\\nThis page lists awesome projects built on top of Transformers. Transformers is more than a toolkit to use pretrained\\nmodels: it's a community of projects built around it and the Hugging Face Hub. We want Transformers to enable\\ndevelopers, researchers, students, professors, engineers, and anyone else to build their dream projects.\\n\\nIn this list, we showcase incredibly impactful and novel projects that have pushed the field forward. We celebrate\\n100 of these projects as we reach the milestone of 100k stars as a community; but we're very open to pull requests\\nadding other projects to the list. If you believe a project should be here and it's not, then please, open a PR \\nto add it.\\n\\n\",\n",
       " '\\n\\ngpt4all\\n\\ngpt4all is an ecosystem of open-source chatbots trained on massive collections of clean assistant data including code, stories and dialogue. It offers open-source, large language models such as LLaMA and GPT-J trained in an assistant-style.\\n\\nKeywords: Open-source, LLaMa, GPT-J, instruction, assistant\\n\\n',\n",
       " '\\n\\nrecommenders\\n\\nThis repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. It goes over several aspects required to build efficient recommendation systems: data preparation, modeling, evaluation, model selection & optimization, as well as operationalization\\n\\nKeywords: Recommender systems, AzureML\\n\\n',\n",
       " '\\n\\nlama-cleaner\\n\\nImage inpainting tool powered by Stable Diffusion. Remove any unwanted object, defect, people from your pictures or erase and replace anything on your pictures.\\n\\nKeywords: inpainting, SD, Stable Diffusion\\n\\n',\n",
       " '\\n\\nflair\\n\\nFLAIR is a powerful PyTorch NLP framework, convering several important tasks: NER, sentiment-analysis, part-of-speech tagging, text and document embeddings, among other things.\\n\\nKeywords: NLP, text embedding, document embedding, biomedical, NER, PoS, sentiment-analysis\\n\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader('./docs').load_data()\n",
    "documents = [doc.text for doc in documents if doc.text != '']\n",
    "\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(cohere_api_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying using co.rerank to find relevant documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Rank: 1, Document Index: 1\n",
      "Document: \n",
      "\n",
      "gpt4all\n",
      "\n",
      "gpt4all is an ecosystem of open-source chatbots trained on massive collections of clean assistant data including code, stories and dialogue. It offers open-source, large language models such as LLaMA and GPT-J trained in an assistant-style.\n",
      "\n",
      "Keywords: Open-source, LLaMa, GPT-J, instruction, assistant\n",
      "\n",
      "\n",
      "Relevance Score: 0.98\n",
      "\n",
      "\n",
      "Document Rank: 2, Document Index: 14\n",
      "Document: \n",
      "\n",
      "DeepPavlov\n",
      "\n",
      "DeepPavlov is an open-source conversational AI library. It is designed for the development of production ready chat-bots and complex conversational systems, as well as research in the area of NLP and, particularly, of dialog systems.\n",
      "\n",
      "Keywords: Conversational, Chatbot, Dialog\n",
      "\n",
      "\n",
      "Relevance Score: 0.96\n",
      "\n",
      "\n",
      "Document Rank: 3, Document Index: 25\n",
      "Document: \n",
      "\n",
      "argilla\n",
      "\n",
      "Argilla is an open-source platform providing advanced NLP labeling, monitoring, and workspaces. It is compatible with many open source ecosystems such as Hugging Face, Stanza, FLAIR, and others.\n",
      "\n",
      "Keywords: NLP, Labeling, Monitoring, Workspaces\n",
      "\n",
      "\n",
      "Relevance Score: 0.62\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Where can I find open source chatbots?\"\n",
    "\n",
    "results = co.rerank(query=query, documents=documents, top_n=3, model='rerank-english-v2.0') \n",
    "for idx, r in enumerate(results):\n",
    "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
    "  print(f\"Document: {r.document['text']}\")\n",
    "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the given markdown about transformer projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_of_the_documents = documents[:len(documents)//2] # due to character limit\n",
    "\n",
    "response = co.summarize( \n",
    "    text='\\n'.join(half_of_the_documents),\n",
    "    model='summarize-xlarge', \n",
    "    length='medium',\n",
    "    extractiveness='medium'\n",
    ")\n",
    "\n",
    "summary = response.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This page lists awesome projects built on top of Transformers. Transformers is more than a toolkit to use pretrained models: it's a community of projects built around it and the Hugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyone else to build their dream projects. In this list, we showcase incredibly impactful and novel projects that have pushed the field forward. We celebrate 100 of these projects as we reach the milestone of 100k stars as a community; but we're very open to pull requests adding other projects to the list. If you believe a project should be here and it's not, then please, open a PR to add it.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
